import argparse
import os

import numpy as np
import pandas as pd
from imblearn.over_sampling import SMOTE, RandomOverSampler
from sklearn import metrics
from sklearn.feature_selection import RFECV
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn_porter import Porter
from sklearn.model_selection import StratifiedKFold

parser = argparse.ArgumentParser(description='Train a decision tree to recognize headings.')
parser.add_argument('dataset_dir', help='folder containing the .csv files generated by build_dataset.py')
parser.add_argument('out_dir', help='folder in which to save the trained model')
args = parser.parse_args()

dataset_dir = args.dataset_dir
paths = os.listdir(dataset_dir)
X = []
y = []
for path in paths:
    df = pd.read_csv(os.path.join(dataset_dir, path), header=0)

    if len(df) < 3:
        continue
    
    df['is_bold'] = df['is_bold'].apply(lambda x: 1 if x else 0)
    df['label'] = df['label'].apply(lambda x: 0 if x == 'paragraph' else 1)
    df['title_case'] = df['title_case'].apply(lambda x: 1 if x else 0)

    print(df.head())

    X.append([0,
                    df['font_size'][0] / df['font_size'][1],
                    df['is_bold'][0],
                    int(df['line'][0].isupper()),
                    0,
                    df['word_count'][0] / df['word_count'][1],
                    int(df['title_case'][0]),
                    0,
                    int(df['color'][1] == df['color'][0])])
    for i in range(len(df)):
        if i > 0 and i < len(df) - 1:
            prev_font_size = df['font_size'][i - 1]
            font_size = df['font_size'][i]
            next_font_size = df['font_size'][i + 1]

            X.append([font_size / prev_font_size,
                            font_size / next_font_size,
                            df['is_bold'][i],
                            int(df['line'][i].isupper()),
                            df['word_count'][i] / df['word_count'][i - 1],
                            df['word_count'][i] / df['word_count'][i + 1],
                            int(df['title_case'][i]),
                            int(df['color'][i] == df['color'][i - 1]),
                            int(df['color'][i] == df['color'][i + 1])])

    X.append([df['font_size'][len(df) - 1] / df['font_size'][len(df) - 2],
                    0,
                    df['is_bold'][len(df) - 1],
                    int(df['line'][len(df) - 1].isupper()),
                    df['word_count'][len(df) - 1] / df['word_count'][len(df) - 2],
                    0,
                    int(df['title_case'][len(df) - 1]),
                    int(df['color'][len(df) - 1] == df['color'][len(df) - 2]),
                    0])

    y = y + list(df['label'])

parameters = {'min_samples_leaf':[1,2,3,4,5,6,7,8,9], 'min_samples_split':[2,3,4,5,6,7,8,9], 'criterion':['entropy']}
clf = GridSearchCV(DecisionTreeClassifier(), parameters, cv=StratifiedKFold(5)).fit(X, y)
clf = DecisionTreeClassifier(min_samples_leaf=clf.best_params_['min_samples_leaf'], min_samples_split=clf.best_params_['min_samples_split'], criterion='entropy')

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)

print('length of training set before SMOTE: ', len(y_train))
smt = SMOTE()
X_train, y_train = smt.fit_sample(X_train, y_train)
print('length of training set after SMOTE: ', len(y_train))

selector = RFECV(clf, step=1, cv=10, scoring=metrics.make_scorer(metrics.f1_score))
selector = selector.fit(X_train, y_train)

print(selector.support_)
print(selector.ranking_)

y_pred = selector.predict(X_test)

print('f1:', metrics.f1_score(y_pred, y_test))
print('IoU:', metrics.jaccard_score(y_pred, y_test))
print('AuC:', metrics.roc_auc_score(y_pred, y_test))

porter = Porter(selector.estimator_, language='js')
output = porter.export(embed_data=True)

with open(os.path.join(args.out_dir, 'model.js'), mode='w+', encoding='utf8') as f:
    f.write('export ' + output)
